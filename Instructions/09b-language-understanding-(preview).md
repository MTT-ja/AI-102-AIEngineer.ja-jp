---
lab:
  title: Azure AI Language サービスで会話言語理解モデルを作成する
  module: Module 5 - Create language understanding solutions
---

# 言語サービスで言語理解モデルを作成する

> [!NOTE]
> Azure AI Language サービスの会話言語理解機能は、現在プレビュー段階であり、変更される可能性があります。 場合によっては、モデルのトレーニングに失敗することがありますが、その場合はもう一度やり直してください。  

Azure AI Language サービスを使用すると、*会話言語理解* モデルを定義できます。このサービスによって、アプリケーションがユーザーからの自然言語入力を解釈し、ユーザーの*意図* (達成したいこと) を予測し、その意図を適用する必要がある*エンティティ*を特定することができます。

たとえば、時計アプリケーション用の会話言語モデルは、次のような入力を処理することが期待される場合があります。

*What's the time in London?* (ロンドンの時刻は何時ですか?)

この種の入力は、*発話* (ユーザーが言うまたは入力する可能性のあるもの) の例です。*意図* は、特定の場所 (*エンティティ*) (この場合はロンドン) の時刻を得ることです。

> [!NOTE]
> 会話言語モデルのタスクは、ユーザーの意図を予測し、意図が適用されるエンティティを特定することです。 意図を満たすために必要なアクションを実際に実行することは、会話言語モデルの仕事では<u>ありません</u>。 たとえば、時計アプリケーションは会話言語モデルを使用して、ユーザーがロンドンの時刻を知りたいことを識別できます。ただし、クライアント アプリケーション自体は、正しい時刻を決定してユーザーに提示するロジックを実装する必要があります。

## Azure AI Language リソースを作成する

会話言語モデルを作成するには、サポートされているリージョンの **Azure AI Language サービス** リソースが必要です。

1. Azure portal (`https://portal.azure.com`) を開き、ご利用の Azure サブスクリプションに関連付けられている Microsoft アカウントを使用してサインインします。
1. 上部にある検索フィールドで「**Azure AI サービス**」を検索します。 次に結果で、[**言語サービス**] の下の [**作成**] を選択します。
1. **[リソースの作成を続行する]** を選択します。
1. 次の設定を使用してリソースをプロビジョニングします。
    - **[サブスクリプション]**: *お使いの Azure サブスクリプション*。
    - **リソース グループ**: *リソース グループを選択または作成します (制限付きサブスクリプションを使用している場合は、新しいリソース グループを作成する権限がないことがあります。その場合は、提供されているものを使用してください)*。
    - **リージョン**: 米国西部 2 または西ヨーロッパ。
    - **[名前]**: *一意の名前を入力します*。
    - **価格レベル**: Free が利用できない場合、**Free (F0)** または **Standard (S)** のいずれかを選択します。
    - **責任ある AI 通知**: 同意。
1. **[Review + create](レビュー + 作成)** を選択します。
1. デプロイが完了するまで待ち、デプロイの詳細を表示します。

## 会話言語理解プロジェクトを作成する

作成リソースを作成したら、それを使って会話言語理解プロジェクトを作成できます。

1. 新しいブラウザー タブで Language Studio ポータル (`https://language.cognitive.azure.com/`) を開き、お使いの Azure サブスクリプションに関連付けられている Microsoft アカウントを使ってサインインします。

1. 言語リソースの選択を求めるメッセージが表示されたら、次の設定を選択します。

    - **Azure ディレクトリ**: ご利用のサブスクリプションを含む Azure ディレクトリ
    - **Azure サブスクリプション**: ご利用の Azure サブスクリプション
    - **リソースの種類**: 言語。
    - **言語リソース**: 以前に作成した Azure AI Language リソース。

1. 言語リソースの選択を求めるメッセージが表示<u>されない</u>場合、原因として、別の Azure AI Language リソースが既に割り当てられていることが考えられます。その場合は、次の操作を行います。

    1. ページの上部にあるバーで、[**設定**] (⚙) ボタンを選択します。
    2. **[設定]** ページで、**[リソース]** タブを表示します。
    3. 先ほど作成した言語リソースを選択し、[**リソースの切り替え**] を選択します。
    4. ページの上部で、[**Language Studio**] を選択して、Language Studio のホーム ページに戻ります。

1. ポータルの上部にある **[新規作成]** メニューで、**[会話言語理解]** を選択します。

1. [**プロジェクトの作成**] ダイアログ ボックスの [**基本情報の入力**] ページで、次の詳細を入力し、[**次へ**] を選択します。
    - **名前**: `Clock`
    - **説明**: `Natural language clock`
    - **発話の主要言語**: 英語
    - **プロジェクトで複数の言語を有効にする**: *オフ*

1. [**確認と完了**] ページで、[**作成**] を選択します。

## 意図の作成

新しいプロジェクトで最初に行うことは、いくつかの意図を定義することです。

> **ヒント**: プロジェクトの作業中に、ヒントがいくつか表示されていたら、そのヒントを読み、[**了解**] を選択して閉じるか、[**すべてスキップ**] を選択します。

1. **[スキーマ定義]** ページの **[意図]** タブで **[&#65291; 追加]** を選び、**GetTime** という新しい意図を追加します。

1. 新しい **GetTime** インテントを選択して編集し、ユーザー入力の例として次の発話を追加します。

    `what is the time?`

    `what's the time?`

    `what time is it?`

    `tell me the time`

1. これらの発話を追加したら、[**変更の保存**] を選択し、[**スキーマ定義**] ページに戻ります。

1. 次の発話を指定して **GetDay** という別の新しい意図を追加します。

    `what day is it?`

    `what's the day?`

    `what is the day today?`

    `what day of the week is it?`

1. これらの発話を追加したら、保存して **[スキーマ定義]** ページに戻り、次の発話を指定して **GetDate** という名前の別の新しい意図を追加します。

    `what date is it?`

    `what's the date?`

    `what is the date today?`

    `what's today's date?`

1. これらの発話を追加したら、保存し、発話ページの **GetDate** フィルターをクリアして、すべての意図のすべての発話を確認できるようにします。 これを行うには、[トレーニング セット] タブの右上にあるフィルター ボタンを選択し、**GetDate** の選択を解除します。

## モデルのトレーニングとテスト

意図をいくつか追加したので、言語モデルをトレーニングして、ユーザー入力から正しく予測できるかどうかを確認しましょう。

1. 左側のウィンドウで [**トレーニング ジョブ**] を選択します。 [**+ トレーニング ジョブの開始**] を選択します。

1. [**トレーニング ジョブの開始**] ダイアログで、新しいモデルをトレーニングするオプションを選択し、「**Clock**」という名前を付けます。

1. モデルのトレーニング プロセスを開始するには、[**トレーニング**] をクリックします。

1. トレーニングが完了した場合 (数分かかることがあります)、ジョブの **[状態]** が " **トレーニング成功**" に変わります。

1. **[モデルのパフォーマンス]** ページを選択して、 **[Clock]** モデルを選択します。 全体と意図ごとの評価メトリック ( *"精度"* 、 *"再現率"* 、 *"F1 スコア"* ) と、トレーニング時に行った評価で生成された *"混同行列"* を確認します (サンプル発話数が少ないため、すべての意図が結果に含まれていない可能性がある点に注意してください)。

    > [!NOTE]
> > 評価メトリックの詳細については、「[ドキュメント](https://learn.microsoft.com/azure/ai-services/language-service/conversational-language-understanding/concepts/evaluation-metrics)」を参照してください。

1. [**モデルのデプロイ**] ページに移動して、[**デプロイの追加**] を選択します。

1. [**デプロイの追加**] ダイアログで、[**新しいデプロイ名の作成**] を選択し、「**production**」と入力します。

1. [**モデル**] フィールドで **Clock** モデルを選択し、[**デプロイ**] を選択します。 デプロイには少し時間がかかることがあります。

1. モデルがデプロイされたら、[**デプロイのテスト**] ページを選択し、[**デプロイ名**] フィールドで**運用環境**のデプロイを選択します。

1. 空白のテキストボックスに次のテキストを入力し、[**テストの実行**] を選択します。

    `what's the time now?`

    返された結果を確認します。予測された意図 (**GetTime** であるはずです) と、予測された意図に対してモデルが計算した確率を示す信頼スコアが含まれていることに注意してください。 [JSON] タブには、考えられる各意図の信頼度の比較が表示されます (信頼度スコアが最も高いものが予測された意図です)

1. テキスト ボックスをクリアし、次のテキストを使って別のテストを実行します。

    `tell me the time`

    もう一度、予測された意図と信頼スコアを確認します。

1. 次のテキストを試します。

    `what's the day today?`

    うまくいけば、モデルは **GetDay** 意図を予測します。

## 複数エンティティの追加

これまで、意図にマップするいくつかの簡単な発話を定義しました。 ほとんどの実際のアプリケーションには、より複雑な発話が含まれており、意図のコンテキストを増やすために、特定のデータ エンティティを抽出する必要があります。

### 学習済み エンティティを追加する

最も一般的な種類のエンティティは *学習済み* エンティティであり、モデルは例に基づいてエンティティ値を識別することを学習します。

1. Language Studio の **[スキーマ定義]** ページに戻り、 **[エンティティ]** タブで **[&#65291; 追加]** を選んで新しいエンティティを追加します。

1. [**エンティティの追加**] ダイアログ ボックスで、エンティティ名「**Location**」を入力し、[**学習済み**] タブが選択されていることを確認します。 [**エンティティの追加**] を選択します。

1. **Location** エンティティが作成されたら、 **[スキーマ定義]** ページに戻り、 **[意図]** タブで **[GetTime]** 意図を選びます。

1. 次の新しい発話例を入力します。

    `what time is it in London?`

1. 発話が追加されたら、**London** という単語を選び、表示されるドロップダウン リストで **Location** を選んで、"London" が場所の例であることを示します。

1. 別の発話例を追加します。

    `Tell me the time in Paris?`

1. 発話が追加されたら、**Paris** という単語を選び、それを **Location** エンティティにマップします。

1. 別の発話例を追加します。

    `what's the time in New York?`

1. 発話が追加されたら、**New York** という単語を選択し、それらを **Location** エンティティにマップします。

1. [**変更の保存**] を選択して新しい発話を保存します。

### *リスト* エンティティを追加する

場合によっては、エンティティの有効な値を特定の用語と同義語のリストに制限できます。これは、アプリが発話内のエンティティのインスタンスを識別するのに役立ちます。

1. Language Studio の **[スキーマ定義]** ページに戻り、 **[エンティティ]** タブで **[&#65291; 追加]** を選んで新しいエンティティを追加します。

1. [**エンティティの追加**] ダイアログ ボックスで、エンティティ名「**Weekday**」を入力し、[**リスト**] エンティティ タブを選択します。次に、[**エンティティの追加**] を選択します。

1. **Weekday** エンティティのページの [**リスト**] セクションで、[**＋ 新しいリストの追加**] をクリックします。 次の値と同意語を入力し、[**保存**] を選択します。

    | キーの一覧表示 | シノニム|
    |-------------------|---------|
    | Sunday | Sun |

1. 前の手順を繰り返して、次のリスト コンポーネントを追加します。

    | 値 | シノニム|
    |-------------------|---------|
    | Monday | Mon |
    | Tuesday | Tue、Tues |
    | Wednesday | Wed、Weds |
    | Thursday | Thur、Thurs |
    | Friday | Fri |
    | Saturday | Sat |

1. **[スキーマ定義]** ページに戻り、 **[意図]** タブで **[GetDate]** 意図を選びます。

1. 次の新しい発話例を入力します。

    `what date was it on Saturday?`

1. 発話が追加されたら、***Saturday*** という単語を選び、表示されるドロップダウン リストで **Weekday** を選びます。

1. 別の発話例を追加します。

    `what date will it be on Friday?`

1. 発話が追加されたら、**Friday** を **Weekday** エンティティにマップします。

1. 別の発話例を追加します。

    `what will the date be on Thurs?`

1. 発話が追加されたら、**Thurs** を **Weekday** エンティティにマップします。

1. [**変更の保存**] を選択して新しい発話を保存します。

### *事前構築済み* エンティティを追加する

Azure AI Language サービスには、会話アプリケーションでよく使われる*事前構築済み*エンティティのセットが用意されています。

1. Language Studio の **[スキーマ定義]** ページに戻り、 **[エンティティ]** タブで **[&#65291; 追加]** を選んで新しいエンティティを追加します。

1. [**エンティティの追加**] ダイアログ ボックスで、エンティティ名「**Date**」を入力し、[**事前構築済み**] エンティティ タブを選択します。次に、[**エンティティの追加**] を選択します。

1. **Date** エンティティのページの [**事前構築済み**] セクションで、[**＋ 新しい事前構築済みの追加**] をクリックします。

1. [**事前構築済みの選択**] リストで **DateTime** を選び、[**保存**] を選択します。

1. **[スキーマ定義]** ページに戻り、 **[意図]** タブで **[GetDay]** 意図を選びます。

1. 次の新しい発話例を入力します。

    `what day was 01/01/1901?`

1. 発話が追加されたら、***01/01/1901*** を選び、表示されるドロップダウン リストで **Date** を選びます。

1. 別の発話例を追加します。

    `what day will it be on Dec 31st 2099?`

1. 発話が追加されたら、**Dec 31st 2099** を **Date** エンティティにマップします。

1. [**変更の保存**] を選択して新しい発話を保存します。

### モデルの再トレーニング

スキーマを変更したので、モードを再トレーニングして再テストする必要があります。

1. **[トレーニング ジョブ]** ページで、 **[トレーニング ジョブの開始]** を選択します。

1. [**トレーニング ジョブの開始**] ダイアログで、[**既存のモデルを上書きする**] を選び、**Clock** モデルを指定します。 [**トレーニング**] を選択してモデルをトレーニングします。 メッセージが表示されたら、既存のモデルを上書きすることを確認します。

1. トレーニングが完了した場合、ジョブの **[状態]** が " **トレーニング成功**" に更新されます。

1. **[モデルのパフォーマンス]** ページを選択して、 **[Clock]** モデルを選択します。 評価メトリック (*精度*、*リコール*、*F1 スコア*) と、トレーニング時に行った評価で生成された*混同行列*を確認します (サンプル発話数が少ないため、すべてのインテントが結果に含まれていない可能性がある点に注意してください)。

1. **[モデルの展開]** ページで、 **[デプロイの追加]** を選択します。

1. **[デプロイの追加]** ダイアログで、**[既存のデプロイ名をオーバーライドする]** を選択し、「**production**」を選択します。

1. [**モデル**] フィールドで **Clock** モデルを選択し、[**デプロイ**] を選択してデプロイします。 これには時間がかかる場合があります。

1. モデルが展開されたら、[**デプロイのテスト**] ページで [**デプロイ名**] フィールドの下にある [**production**] を選択して、次のテキストでモデルをテストします。

    `what's the time in Edinburgh?`

1. 返された結果を確認します。**GetTime** 意図と、テキスト値が "Edinburgh" の **Location** エンティティが予測されるはずです。

1. 次の発話をテストしてみてください。

    `what time is it in Tokyo?`

    `what date is it on Friday?`

    `what's the date on Weds?`

    `what day was 01/01/2020?`

    `what day will Mar 7th 2030 be?`

## クライアント アプリからモデルを使う

実際のプロジェクトでは、予測パフォーマンスに満足するまで、意図とエンティティを繰り返し改良し、再トレーニングして、再テストします。 次に、モデルをテストしてその予測のパフォーマンスに満足したら、REST インターフェイスを呼び出してクライアント アプリで使用できます。 この演習では、*curl* ユーティリティを使って、モデルの REST エンドポイントを呼び出します。

1. Language Studio の [**モデルのデプロイ**] ページで [**production**] を選びます。 [**予測 URL の取得**] を選択します。

1. [**予測 URL の取得**] ダイアログ ボックスに予測エンドポイントの URL とサンプル要求が表示されていることに注意してください。この要求はヘッダーに Azure AI 言語リソースのキーが指定されており、要求データにクエリと言語を含み、HTTP POST 要求をエンドポイントに送信する **curl** コマンドで構成されています。

## Azure Cloud Shell から API を呼び出す

新しいインターネット ブラウザのタブを開いて、Cloud Shell を操作します。

1. [Azure portal](https://portal.azure.com?azure-portal=true) で、ページ上部の検索ボックスの右側にある **[>_]** (*Cloud Shell*) ボタンを選びます。 ポータルの下部に Cloud Shell ペインが開きます。

    ![上部の検索ボックスの右側にあるアイコンをクリックして Cloud Shell を開始している状態のスクリーンショット。](images/cloudshell-launch-portal.png#lightbox)

1. Cloud Shell を初めて開くと、使用するシェルの種類 (*Bash* または *PowerShell*) を選択するように求められる場合があります。 **[Bash]** を選択します。 このオプションが表示されない場合は、この手順をスキップします。  

1. Cloud Shell のストレージを作成するように求めるメッセージが表示された場合は、お使いのサブスクリプションが指定されていることを確認して、**[ストレージの作成]** を選択します。 その後、ストレージが作成されるのを 1 分程度待ちます。

1. Cloud Shell ペインの左上に表示されるシェルの種類が *Bash* に切り替えられたことを確認します。 *PowerShell* の場合、左上にあるドロップダウン メニューを使用して [*Bash*] に切り替えます。

1. ターミナルが起動したら、次のコマンドを実行して、リポジトリのコピーを Cloud Shell にダウンロードします。

    ```bash
    rm -r azure-ai-eng -f
    git clone https://github.com/MicrosoftLearning/AI-102-AIEngineer azure-ai-eng
    ```

1. ファイルは **azure-ai-eng** というフォルダーにダウンロードされています。 次を実行して、そのフォルダーに移動します。

    ```bash
    cd azure-ai-eng/09-language-app
    ```

1. `code send-call.sh` を実行して、ファイルを Cloud Shell エディターで開きます。 このファイルには、「シドニーの時刻は何時ですか?」という質問でサービスを呼び出すスクリプトが含まれています。
1. Language Studio からのサンプル要求の対応する値から、次の値を置き換えます。

    - **<ENDPOINT_URL>**: エンドポイントの URL。`https://my-service.cognitiveservices.azure.com/language/:analyze-conversations?api-version=2022-10-01-preview` のようになります。
    - **<YOUR_KEY>**: 使用するキー。 `b11bcsbd50a149dfb6626791d20f514b` のようになります。
    - <**REQUEST_ID>**: 要求 ID。 `4vfdad1c-b2fc-48ba-bd7d-b59d2242395b` のようになります。

1. **Ctrl + S** キーを押して、変更内容を保存します。
1. `sh send-call.sh` を実行して呼び出します。
1. 結果の JSON を確認します。これには予測された意図とエンティティが含まれています。

    ```json
    {
      "kind": "ConversationResult",
      "result": {
        "query": "What's the time in Sydney",
        "prediction": {
          "topIntent": "GetTime",
          "projectKind": "Conversation",
          "intents": [
            {
              "category": "GetTime",
              "confidenceScore": 0.9135122
            },
            {
              "category": "GetDay",
              "confidenceScore": 0.61633164
            },
            {
              "category": "GetDate",
              "confidenceScore": 0.601757
            },
            {
              "category": "None",
              "confidenceScore": 0
            }
          ],
          "entities": [
            {
              "category": "Location",
              "text": "Sydney",
              "offset": 19,
              "length": 6,
              "confidenceScore": 1
            }
          ]
        }
      }
    }
    ```

1. モデルから返された JSON 応答を確認し、予測された最高スコアの意図が **GetTime** であることを確認します。

1. curl コマンドのクエリを `What's today's date?` に変更してから実行し、結果の JSON を確認します。

1. 次のクエリを試します。

    `What day will Jan 1st 2050 be?`

    `What time is it in Glasgow?`

    `What date will next Monday be?`

## プロジェクトをエクスポートする

Language Studio を使って言語理解モデルを開発およびテストできますが、DevOps のソフトウェア開発プロセスでは、継続的インテグレーションとデリバリー (CI/CD) パイプラインに含めることができるプロジェクトのソース制御定義を維持する必要があります。 コード スクリプトで Azure AI Language REST API を使ってモデルを作成およびトレーニングすることもできますが、より簡単な方法は、ポータルを使ってモデル スキーマを作成し、別の Azure AI Language サービス インスタンスにインポートして再トレーニングできるように **.json** ファイルとしてエクスポートすることです。 このアプローチにより、モデルの移植性と再現性を維持しながら、Language Studio ビジュアル インターフェイスの生産性のメリットを活用できます。

1. [**プロジェクト**] タブを選択し、円アイコンを選択して **Clock** プロジェクトを選択します。

1. [**⤓ エクスポート**] ボタンを選択します。

1. 生成された **Clock.json** ファイルを (任意の場所に) 保存します。

1. ダウンロードしたファイルを好みのコード エディター (Visual Studio Code など) で開き、プロジェクトの JSON 定義を確認します。

## 詳細情報

**Azure AI Language** サービスを使って会話言語理解ソリューションを作成する方法の詳細については、「[Azure AI Language のドキュメント](/azure/ai-services/language-service/conversational-language-understanding/overview)」を参照してください。
